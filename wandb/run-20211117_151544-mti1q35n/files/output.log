/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:1802: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast
  FutureWarning,
/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:1828: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast
  FutureWarning,
[34m[1mwandb[39m[22m: logging graph, to disable use `wandb.watch(log_graph=False)`
  0%|                                                                                         | 0/68 [00:00<?, ?it/s]
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
â”œâ”€ResNet: 1-1                            [-1, 20]                  --
|    â””â”€Conv2d: 2-1                       [-1, 64, 256, 256]        9,408
|    â””â”€BatchNorm2d: 2-2                  [-1, 64, 256, 256]        128
|    â””â”€ReLU: 2-3                         [-1, 64, 256, 256]        --
|    â””â”€MaxPool2d: 2-4                    [-1, 64, 128, 128]        --
|    â””â”€Sequential: 2-5                   [-1, 64, 128, 128]        --
|    |    â””â”€BasicBlock: 3-1              [-1, 64, 128, 128]        73,984
|    |    â””â”€BasicBlock: 3-2              [-1, 64, 128, 128]        73,984
|    â””â”€Sequential: 2-6                   [-1, 128, 64, 64]         --
|    |    â””â”€BasicBlock: 3-3              [-1, 128, 64, 64]         230,144
|    |    â””â”€BasicBlock: 3-4              [-1, 128, 64, 64]         295,424
|    â””â”€Sequential: 2-7                   [-1, 256, 32, 32]         --
|    |    â””â”€BasicBlock: 3-5              [-1, 256, 32, 32]         919,040
|    |    â””â”€BasicBlock: 3-6              [-1, 256, 32, 32]         1,180,672
|    â””â”€Sequential: 2-8                   [-1, 512, 16, 16]         --
|    |    â””â”€BasicBlock: 3-7              [-1, 512, 16, 16]         3,673,088
|    |    â””â”€BasicBlock: 3-8              [-1, 512, 16, 16]         4,720,640
|    â””â”€AdaptiveAvgPool2d: 2-9            [-1, 512, 1, 1]           --
|    â””â”€Sequential: 2-10                  [-1, 20]                  --
|    |    â””â”€Linear: 3-9                  [-1, 512]                 262,656
|    |    â””â”€BatchNorm1d: 3-10            [-1, 512]                 1,024
|    |    â””â”€Dropout: 3-11                [-1, 512]                 --
|    |    â””â”€Linear: 3-12                 [-1, 512]                 262,656
|    |    â””â”€BatchNorm1d: 3-13            [-1, 512]                 1,024
|    |    â””â”€Dropout: 3-14                [-1, 512]                 --
|    |    â””â”€Linear: 3-15                 [-1, 20]                  10,260
==========================================================================================
Total params: 11,714,132
Trainable params: 11,714,132
Non-trainable params: 0
Total mult-adds (G): 9.41
==========================================================================================
Input size (MB): 3.00
Forward/backward pass size (MB): 184.02
Params size (MB): 44.69
Estimated Total Size (MB): 231.70
==========================================================================================
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
â”œâ”€ResNet: 1-1                            [-1, 20]                  --
|    â””â”€Conv2d: 2-1                       [-1, 64, 256, 256]        9,408
|    â””â”€BatchNorm2d: 2-2                  [-1, 64, 256, 256]        128
|    â””â”€ReLU: 2-3                         [-1, 64, 256, 256]        --
|    â””â”€MaxPool2d: 2-4                    [-1, 64, 128, 128]        --
|    â””â”€Sequential: 2-5                   [-1, 64, 128, 128]        --
|    |    â””â”€BasicBlock: 3-1              [-1, 64, 128, 128]        73,984
|    |    â””â”€BasicBlock: 3-2              [-1, 64, 128, 128]        73,984
|    â””â”€Sequential: 2-6                   [-1, 128, 64, 64]         --
|    |    â””â”€BasicBlock: 3-3              [-1, 128, 64, 64]         230,144
|    |    â””â”€BasicBlock: 3-4              [-1, 128, 64, 64]         295,424
|    â””â”€Sequential: 2-7                   [-1, 256, 32, 32]         --
|    |    â””â”€BasicBlock: 3-5              [-1, 256, 32, 32]         919,040
|    |    â””â”€BasicBlock: 3-6              [-1, 256, 32, 32]         1,180,672
|    â””â”€Sequential: 2-8                   [-1, 512, 16, 16]         --
|    |    â””â”€BasicBlock: 3-7              [-1, 512, 16, 16]         3,673,088
|    |    â””â”€BasicBlock: 3-8              [-1, 512, 16, 16]         4,720,640
|    â””â”€AdaptiveAvgPool2d: 2-9            [-1, 512, 1, 1]           --
|    â””â”€Sequential: 2-10                  [-1, 20]                  --
|    |    â””â”€Linear: 3-9                  [-1, 512]                 262,656
|    |    â””â”€BatchNorm1d: 3-10            [-1, 512]                 1,024
|    |    â””â”€Dropout: 3-11                [-1, 512]                 --
|    |    â””â”€Linear: 3-12                 [-1, 512]                 262,656
|    |    â””â”€BatchNorm1d: 3-13            [-1, 512]                 1,024
|    |    â””â”€Dropout: 3-14                [-1, 512]                 --
|    |    â””â”€Linear: 3-15                 [-1, 20]                  10,260
==========================================================================================
Total params: 11,714,132
Trainable params: 11,714,132
Non-trainable params: 0
Total mult-adds (G): 9.41
==========================================================================================
Input size (MB): 3.00
Forward/backward pass size (MB): 184.02
Params size (MB): 44.69
Estimated Total Size (MB): 231.70


























TRAIN LOOP E: 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:58<00:00,  1.17it/s, LOSS=3.33, ACC=0.14]

VALID LOOP E: 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 12/17 [00:03<00:00,  5.59it/s, LOSS=20.7, ACC=0.181]
VALID LOOP E: 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.94it/s, LOSS=22.4, ACC=0.179]
/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:370: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  "please use `get_last_lr()`.", UserWarning)
























TRAIN LOOP E: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:56<00:00,  1.21it/s, LOSS=3.47, ACC=0.162]


VALID LOOP E: 1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 15/17 [00:03<00:00,  5.14it/s, LOSS=4, ACC=0.151]
VALID LOOP E: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.82it/s, LOSS=3.96, ACC=0.151]

























TRAIN LOOP E: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:57<00:00,  1.18it/s, LOSS=3.36, ACC=0.153]

VALID LOOP E: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.97it/s, LOSS=375, ACC=0.153]






















TRAIN LOOP E: 3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 60/68 [00:51<00:06,  1.18it/s, LOSS=3.35, ACC=0.16]
Traceback (most recent call last):
  File "train.py", line 86, in <module>
    for ii,(img_batch,label_batch) in iter_loop:
  File "/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/site-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1186, in _next_data
    idx, data = self._get_data()
  File "/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1142, in _get_data
    success, data = self._try_get_data()
  File "/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 990, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/home/hazemahmed/anaconda3/envs/torch_env/lib/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt